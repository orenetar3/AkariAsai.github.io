<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Akari Asai </title> <meta name="author" content="Akari Asai"> <meta name="description" content="A 5th year Ph.D. student at University of Washington, focusing on NLP and ML. "> <meta name="keywords" content="NLP, ML, LLM"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%95&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://akariasai.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%61%6B%61%72%69@%63%73.%77%61%73%68%69%6E%67%74%6F%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gqB4u_wAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/35584853" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/AkariAsai" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/AkariAsai" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/award/">Awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/press/">Press &amp; Talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">Service </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/example_pdf.pdf">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Akari</span> Asai </h1> <p class="desc">Ph.D. student @ <a href="https://www.cs.washington.edu/" rel="external nofollow noopener" target="_blank">Paul G. Allen School of Computer Science &amp; Engineering, University of Washington</a><br>Visiting Student Researcher @ <a href="https://ai.meta.com/" rel="external nofollow noopener" target="_blank">Meta AI</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?75a5d1636dcad099bc4e41062d2ac8e8" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am currently in my 5th year of pursuing a Ph.D. in NLP at Paul G. Allen School of Computer Science &amp; Engineering, University of Washington. I am fortunate to be advised by <a href="https://homes.cs.washington.edu/~hannaneh/index.html" rel="external nofollow noopener" target="_blank">Prof. Hannaneh Hajishirzi</a>. I am also spending some time at <a href="https://ai.meta.com/research/" rel="external nofollow noopener" target="_blank">Meta AI Research</a> as a visiting student researcher, under the supervision of <a href="https://scottyih.org/" rel="external nofollow noopener" target="_blank">Dr. Wen-tau Yih</a>. Prior to joining UW, I obtained a B.E. in <a href="https://www.ee.t.u-tokyo.ac.jp/en/" rel="external nofollow noopener" target="_blank">Electrical Engineering and Computer Science</a> from The University of Tokyo, Japan.</p> <p>My primary research interests are centered around natural language processing and machine learning. My research is driven by a desire to create NLP systems that are both practical and impactful, with the ultimate goal of improving access to information for people from all walks of life. Recently, my research has focused on several key areas, including:</p> <ul> <li> <p><strong>Retrieval-augmented LMs</strong> – I’ve pioneered and advanced the area of retrieval-augmented LMs to build more reliable, adaptable and attributable intelligent systems: <a href="https://arxiv.org/abs/2310.11511" rel="external nofollow noopener" target="_blank">Self-RAG (ICLR 2024)</a>, <a href="https://arxiv.org/abs/2212.10511" rel="external nofollow noopener" target="_blank">Adaptive Retrieval-augmented LM (ACL 2023)</a>, <a href="https://arxiv.org/abs/2112.08688" rel="external nofollow noopener" target="_blank">Evidentiality-guided RAG (NAACL 2022)</a>, <a href="https://arxiv.org/abs/2401.06855" rel="external nofollow noopener" target="_blank">FAVA (COLM 2024)</a>. I’ve co-taught <a href="https://acl2023-retrieval-lm.github.io/" rel="external nofollow noopener" target="_blank">the first tutorial of retrieval-augmented LMs</a> at ACL 2023. See our latest position paper, <a href="assets/pdf/ralm_position.pdf">Reliable, Adaptive and Attributable LMs with Retrieval (Asai et al., 2024)</a> on why retrieval-augmented LMs could be the next generation of LMs and we should contribute to their advancements together.</p> </li> <li> <p><strong>General-purpose knowledge retrieval systems</strong> – Reliable retrieval systems are the key to build powerful and successful retrieval-augmented LMs. I’ve developed advanced search and representation systems that better capture complex real-world user queries, robust to diverse domains, and are more efficient: <a href="https://openreview.net/forum?id=SJgVHkrYDH" rel="external nofollow noopener" target="_blank">Path Retriever (ICLR 2020)</a>, the <a href="https://arxiv.org/abs/2211.09260" rel="external nofollow noopener" target="_blank">first Instructable Retriever (Findings of ACL 2023)</a>, <a href="https://arxiv.org/abs/2010.01057" rel="external nofollow noopener" target="_blank">LUKE (EMNLP 2020)</a> and <a href="https://arxiv.org/abs/2106.00882" rel="external nofollow noopener" target="_blank">Binary Passage Retriever (ACL 2021)</a>. Our methods have been integrated into multiple real-world systems, such as <a href="https://www.salesforce.com/news/stories/salesforce-research-develops-new-search-engine-to-support-the-fight-against-covid-19/" rel="external nofollow noopener" target="_blank">COVID-19 Research Search</a>.</p> </li> <li> <p><strong>Serving intelligent systems for underrepresented populations</strong> – Today’s NLP systems are primarily developed and tested on a handful of high-resource languages, leaving many world languages left behind. I believe developing NLP systems accessible for everyone is important. I’ve been contributing to the area of multilingual NLP, in particular, advancing our understanding of NLP in low-resource setups and developing systems that can help linguistic minorities to access the information they need: <a href="https://arxiv.org/abs/2010.11856" rel="external nofollow noopener" target="_blank">XOR QA (NAACL 2021)</a>, <a href="https://arxiv.org/abs/2107.11976" rel="external nofollow noopener" target="_blank">CORA (NeurIPS 2021)</a>, <a href="https://arxiv.org/abs/2305.14857" rel="external nofollow noopener" target="_blank">BUFFET (NAACL 2024)</a> and <a href="https://arxiv.org/abs/2211.15649" rel="external nofollow noopener" target="_blank">Large-scale meta survey on multilingual resources (Findings of EMNLP 2022)</a>. I was the lead organizer of <a href="https://mia-workshop.github.io/" rel="external nofollow noopener" target="_blank">Workshop on Multilingual Information Access</a> at NAACL 2022 and hosted the first cross-lingual retrieval and open-domain QA shared task. This line of my work was featured in <a href="https://news.cs.washington.edu/2022/10/20/lost-in-translation-no-more-ibm-fellowship-winner-akari-asai-asks-and-answers-big-questions-in-nlp-to-expand-information-access-to-all/" rel="external nofollow noopener" target="_blank">UW CSE News</a>.</p> </li> </ul> <p>I am also passionate about teaching, mentoring and helping students to learn research, especially students from underrepresented groups. I have been the Head TA for <a href="https://courses.cs.washington.edu/courses/cse473/23au/" rel="external nofollow noopener" target="_blank">CSE473: Intro to AI (undergrad)</a> and <a href="https://koh.pw/cse599j/" rel="external nofollow noopener" target="_blank">CSE599J: Data-centric ML (grad)</a> at UW. To reduce the barrier to start research or Ph.D. in this area, I’m hosting weekly office hours open to everyone (please sign up from <a href="https://calendly.com/akari-asai/office-hour" rel="external nofollow noopener" target="_blank">Calendly</a>!), and am a mentor for <a href="https://www.cs.washington.edu/academics/phd/admissions/pams" rel="external nofollow noopener" target="_blank">UW CSE Ph.D. Pre-Application Mentorship Service (PAMS)</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 15, 2024</th> <td> Our new pre-prints, <a href="https://code-rag-bench.github.io/" rel="external nofollow noopener" target="_blank">CodeRAG-Bench</a>, <a href="https://retrievalscaling.github.io/" rel="external nofollow noopener" target="_blank">Scaling of retrieval datastore</a> and <a href="https://www.arxiv.org/abs/2407.07087" rel="external nofollow noopener" target="_blank">CopyBench</a> are out! </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 10, 2024</th> <td> Our <a href="https://arxiv.org/abs/2401.06855" rel="external nofollow noopener" target="_blank">Fine-grained Hallucination paper</a> has been accepted at the first <a href="https://colmweb.org/" rel="external nofollow noopener" target="_blank">COLM</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">May 07, 2024</th> <td> Attended ICLR 2024 in person and gave an oral presentation for Self-RAG (<a href="assets/pdf/self_rag_oral.pdf">slide</a>)! </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 19, 2024</th> <td> Gave an invited lecture on state of the art of retrieval-augmented generation (<a href="assets/pdf/akari_cmu_anlp_lecture-compressed.pdf">slides</a>) at CMU Advanced NLP class! </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 15, 2024</th> <td> Our <a href="https://buffetfs.github.io/" rel="external nofollow noopener" target="_blank">BUFFET</a>, a large-scale few-shot cross-lingual transfer benchmark across 54 langauges and 15 tasks, has been accepted to <a href="https://2024.naacl.org/" rel="external nofollow noopener" target="_blank">NAACL 2024 main conference</a>! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <p>See my full publications at <a href="https://akariasai.github.io/publications/">the publication page</a>!</p> <ol class="bibliography"> <li> <div class="row"> <div id="asai2024selfrag" class="col-sm-11"> <div class="title">Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection</div> <div class="author"> <em>Akari Asai</em> ,  Zeqiu Wu ,  Yizhong Wang ,  Avirup Sil ,  and  Hannaneh Hajishirzi </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations (ICLR; Oral, Top 1%)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2310.11511.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/AkariAsai/self-rag" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://selfrag.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM’s quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="mallen2022not" class="col-sm-11"> <div class="title">When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories</div> <div class="author"> Alex Mallen* ,  <em>Akari Asai*</em> ,  Victor Zhong ,  Rajarshi Das ,  Daniel Khashabi , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hannaneh Hajishirzi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL; Oral, Best Video Paper Award – Most Viewed)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2212.10511.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AlexTMallen/adaptive-retrieval" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters. This paper aims to understand LMs’ strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments on two open-domain entity-centric QA datasets: PopQA, our new dataset with 14k questions about long-tail entities, and EntityQuestions, a widely used open-domain QA dataset. We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases. Scaling, on the other hand, mainly improves memorization of popular knowledge, and fails to appreciably improve memorization of factual knowledge in the tail. Based on those findings, we devise a new method for retrieval-augmentation that improves performance and reduces inference costs by only retrieving non-parametric memories when necessary.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2023.acl-long.546.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2024retrieval" class="col-sm-11"> <div class="title">Reliable, Adaptable, and Attributable Language Models with Retrieval</div> <div class="author"> <em>Akari Asai</em> ,  Zexuan Zhong ,  Danqi Chen ,  Pang Wei Koh ,  Luke Zettlemoyer , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hannaneh Hajishirzi, Wen-tau Yih' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2403.03187.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and a lack of verifiability. In this position paper, we advocate for retrieval-augmented LMs to replace parametric LMs as the next generation of LMs. By incorporating large-scale datastores during inference, retrieval-augmented LMs can be more reliable, adaptable, and attributable. Despite their potential, retrieval-augmented LMs have yet to be widely adopted due to several obstacles: specifically, current retrieval-augmented LMs struggle to leverage helpful text beyond knowledge-intensive tasks such as question answering, have limited interaction between retrieval and LM components, and lack the infrastructure for scaling. To address these, we propose a roadmap for developing general-purpose retrieval-augmented LMs. This involves a reconsideration of datastores and retrievers, the exploration of pipelines with improved retriever-LM interaction, and significant investment in infrastructure for efficient training and inference.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai-etal-2023-task" class="col-sm-11"> <div class="title">Task-aware Retrieval with Instructions</div> <div class="author"> <em>Akari Asai</em> ,  Timo Schick ,  Patrick Lewis ,  Xilun Chen ,  Gautier Izacard , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sebastian Riedel, Hannaneh Hajishirzi, Wen-tau Yih' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2023 (Findings Spotlight)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2211.09260.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/facebookresearch/tart" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We study the problem of retrieval with instructions, where users of a retrieval system explicitly describe their intent along with their queries. We aim to develop a general-purpose task-aware retrieval system using multi-task instruction tuning, which can follow human-written instructions to find the best documents for a given query. We introduce the first large-scale collection of approximately 40 retrieval datasets with instructions, BERRI, and present TART, a multi-task retrieval system trained on BERRI with instructions. TART shows strong capabilities to adapt to a new retrieval task via instructions and advances the state of the art on two zero-shot retrieval benchmarks, BEIR and LOTTE, outperforming models up to three times larger. We further introduce a new evaluation setup, X^2-Retrieval to better reflect real-world scenarios, where diverse domains and tasks are pooled and a system needs to find documents aligning users’ intents. In this setup, TART significantly outperforms competitive baselines, further demonstrating the effectiveness of guiding retrieval with instructions.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2023.findings-acl.225.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="Yamada2020LUKEDC" class="col-sm-11"> <div class="title">LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention</div> <div class="author"> Ikuya Yamada ,  <em>Akari Asai</em> ,  Hiroyuki Shindo ,  Hideaki Takeda ,  and  Yuji Matsumoto </div> <div class="periodical"> <em>In Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2010.01057.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/studio-ousia/luke" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at this https URL.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2019learning" class="col-sm-11"> <div class="title">Learning to retrieve reasoning paths over wikipedia graph for question answering</div> <div class="author"> <em>Akari Asai</em> ,  Kazuma Hashimoto ,  Hannaneh Hajishirzi ,  Richard Socher ,  and  Caiming Xiong </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/1911.10470.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://blog.salesforceairesearch.com/learning-to-retrieve-reasoning-paths-from-the-wikipedia-graph-for-question-answering/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Answering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions. Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents. Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path. Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="NEURIPS2021_3df07fda" class="col-sm-11"> <div class="title">One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval</div> <div class="author"> <em>Akari Asai</em> ,  Xinyan Yu ,  Jungo Kasai ,  and  Hanna Hajishirzi </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/3df07fdae1ab273a967aaa1d355b8bb6-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AkariAsai/CORA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We present Cross-lingual Open-Retrieval Answer Generation (CORA), the first unified many-to-many question answering (QA) model that can answer questions across many languages, even for ones without language-specific annotated data or knowledge sources.We introduce a new dense passage retrieval algorithm that is trained to retrieve documents across languages for a question.Combined with a multilingual autoregressive generation model, CORA answers directly in the target language without any translation or in-language retrieval modules as used in prior work. We propose an iterative training method that automatically extends annotated data available only in high-resource languages to low-resource ones. Our results show that CORA substantially outperforms the previous state of the art on multilingual open QA benchmarks across 26 languages, 9 of which are unseen during training. Our analyses show the significance of cross-lingual retrieval and generation in many languages, particularly under low-resource settings.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <iframe src="https://slideslive.com/38967665/one-question-answering-model-for-many-languages-with-crosslingual-dense-passage-retrieval" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen width="auto" height="auto"></iframe> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="asai-etal-2021-xor" class="col-sm-11"> <div class="title">XOR QA: Cross-lingual Open-Retrieval Question Answering</div> <div class="author"> <em>Akari Asai</em> ,  Jungo Kasai ,  Jonathan Clark ,  Kenton Lee ,  Eunsol Choi , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hannaneh Hajishirzi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL; Oral)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2021.naacl-main.46.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AkariAsai/XORQA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Multilingual question answering tasks typically assume that answers exist in the same language as the question. Yet in practice, many languages face both information scarcity—where languages have few reference articles—and information asymmetry—where questions reference concepts from other cultures. This work extends open-retrieval question answering to a cross-lingual setting enabling questions from one language to be answered via answer content from another language. We construct a large-scale dataset built on 40K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for. Based on this dataset, we introduce a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingual document retrieval from multilingual and English resources. We establish baselines with state-of-the-art machine translation systems and cross-lingual pretrained models. Experimental results suggest that XOR QA is a challenging task that will facilitate the development of novel techniques for multilingual question answering. Our data and code are available at https://nlp.cs.washington.edu/xorqa/.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2021.naacl-main.46.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%6B%61%72%69@%63%73.%77%61%73%68%69%6E%67%74%6F%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gqB4u_wAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/35584853" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/AkariAsai" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/AkariAsai" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Akari Asai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>